{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataAnalyticsOnTheWebAssignment3DNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-vuVzC7urdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851934ac-0bf7-40d2-fd27-aad08a0842b8"
      },
      "source": [
        "# needed to create the data frame\n",
        "import pandas as pd\n",
        "\n",
        "# create data frame from csv file we hosted on our github\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/1122131uhi/dataAnalytics/master/tutorial2dnndata.csv', index_col=0)\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/20023167uhi/DataAnalytics/main/Python/Data%20Analytics%20on%20the%20Web/Assignment%201/Data/Tom_Blackwood-OHE-Weather_and_Collision_data_for_New_York_boroughs_2012-2020.csv', index_col=0)\n",
        "df.info()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2556 entries, 2013-01-01 to 2019-12-31\n",
            "Data columns (total 23 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   temp        2556 non-null   float64\n",
            " 1   slp         2555 non-null   float64\n",
            " 2   wdsp        2556 non-null   float64\n",
            " 3   April       2556 non-null   int64  \n",
            " 4   August      2556 non-null   int64  \n",
            " 5   December    2556 non-null   int64  \n",
            " 6   February    2556 non-null   int64  \n",
            " 7   January     2556 non-null   int64  \n",
            " 8   July        2556 non-null   int64  \n",
            " 9   June        2556 non-null   int64  \n",
            " 10  March       2556 non-null   int64  \n",
            " 11  May         2556 non-null   int64  \n",
            " 12  November    2556 non-null   int64  \n",
            " 13  October     2556 non-null   int64  \n",
            " 14  September   2556 non-null   int64  \n",
            " 15  Friday      2556 non-null   int64  \n",
            " 16  Monday      2556 non-null   int64  \n",
            " 17  Saturday    2556 non-null   int64  \n",
            " 18  Sunday      2556 non-null   int64  \n",
            " 19  Thursday    2556 non-null   int64  \n",
            " 20  Tuesday     2556 non-null   int64  \n",
            " 21  Wednesday   2556 non-null   int64  \n",
            " 22  collisions  2556 non-null   float64\n",
            "dtypes: float64(4), int64(19)\n",
            "memory usage: 479.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6saFKcySvM9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "fba44f43-a448-47e5-e803-e1a448dc91a4"
      },
      "source": [
        "# make sure we have our data by printing it out\n",
        "df.head(6)\n",
        "# print(df) #all"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temp</th>\n",
              "      <th>slp</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>April</th>\n",
              "      <th>August</th>\n",
              "      <th>December</th>\n",
              "      <th>February</th>\n",
              "      <th>January</th>\n",
              "      <th>July</th>\n",
              "      <th>June</th>\n",
              "      <th>March</th>\n",
              "      <th>May</th>\n",
              "      <th>November</th>\n",
              "      <th>October</th>\n",
              "      <th>September</th>\n",
              "      <th>Friday</th>\n",
              "      <th>Monday</th>\n",
              "      <th>Saturday</th>\n",
              "      <th>Sunday</th>\n",
              "      <th>Thursday</th>\n",
              "      <th>Tuesday</th>\n",
              "      <th>Wednesday</th>\n",
              "      <th>collisions</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-01-01</th>\n",
              "      <td>38.0</td>\n",
              "      <td>1008.8</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.097222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-02</th>\n",
              "      <td>27.5</td>\n",
              "      <td>1013.4</td>\n",
              "      <td>12.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.498747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-03</th>\n",
              "      <td>21.8</td>\n",
              "      <td>1018.1</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.527430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-04</th>\n",
              "      <td>32.2</td>\n",
              "      <td>1015.2</td>\n",
              "      <td>11.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.645503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-05</th>\n",
              "      <td>37.3</td>\n",
              "      <td>1017.3</td>\n",
              "      <td>13.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.095238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-06</th>\n",
              "      <td>35.7</td>\n",
              "      <td>1019.7</td>\n",
              "      <td>5.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.118056</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            temp     slp  wdsp  April  ...  Thursday  Tuesday  Wednesday  collisions\n",
              "date                                   ...                                          \n",
              "2013-01-01  38.0  1008.8  15.0      0  ...         0        1          0    0.097222\n",
              "2013-01-02  27.5  1013.4  12.4      0  ...         0        0          1    0.498747\n",
              "2013-01-03  21.8  1018.1   9.8      0  ...         1        0          0    0.527430\n",
              "2013-01-04  32.2  1015.2  11.3      0  ...         0        0          0    0.645503\n",
              "2013-01-05  37.3  1017.3  13.2      0  ...         0        0          0    0.095238\n",
              "2013-01-06  35.7  1019.7   5.9      0  ...         0        0          0    0.118056\n",
              "\n",
              "[6 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFHPLeD5tHQH",
        "outputId": "f5e3d9e0-791e-4ef1-88d5-201307390bff"
      },
      "source": [
        "# df.drop('gust', axis=1)\r\n",
        "df = df[df['slp'].notna()]\r\n",
        "df.info()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2555 entries, 2013-01-01 to 2019-12-31\n",
            "Data columns (total 23 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   temp        2555 non-null   float64\n",
            " 1   slp         2555 non-null   float64\n",
            " 2   wdsp        2555 non-null   float64\n",
            " 3   April       2555 non-null   int64  \n",
            " 4   August      2555 non-null   int64  \n",
            " 5   December    2555 non-null   int64  \n",
            " 6   February    2555 non-null   int64  \n",
            " 7   January     2555 non-null   int64  \n",
            " 8   July        2555 non-null   int64  \n",
            " 9   June        2555 non-null   int64  \n",
            " 10  March       2555 non-null   int64  \n",
            " 11  May         2555 non-null   int64  \n",
            " 12  November    2555 non-null   int64  \n",
            " 13  October     2555 non-null   int64  \n",
            " 14  September   2555 non-null   int64  \n",
            " 15  Friday      2555 non-null   int64  \n",
            " 16  Monday      2555 non-null   int64  \n",
            " 17  Saturday    2555 non-null   int64  \n",
            " 18  Sunday      2555 non-null   int64  \n",
            " 19  Thursday    2555 non-null   int64  \n",
            " 20  Tuesday     2555 non-null   int64  \n",
            " 21  Wednesday   2555 non-null   int64  \n",
            " 22  collisions  2555 non-null   float64\n",
            "dtypes: float64(4), int64(19)\n",
            "memory usage: 479.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltGRAo1hvO8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b7f029d-65c3-4290-d694-c14d6b8a89d7"
      },
      "source": [
        "# needed to help with speedy maths based calculations\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = df['collisions']\n",
        "X = df.drop('collisions', axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101)\n",
        "\n",
        "X_train.info()\n",
        "X_test.info()\n",
        "\n",
        "print(f\"\"\" \n",
        "{y_train.head()}\n",
        "Length: {len(y_train)}\n",
        "\n",
        "{y_test.head()}\n",
        "Length: {len(y_test)}\n",
        "\"\"\")\n",
        "\n",
        "# iloc allows us to select by rows. Here, we are shuffling the data by rows determined at random.\n",
        "shuffle = df.iloc[np.random.permutation(len(df))]\n",
        "\n",
        "# we are selecting all rows of the columns outliined i.e. The 3rd (2 as indexes start from 0)\n",
        "predictors = shuffle.iloc[:,0:22]\n",
        "# Since it is the last column, we can also use\n",
        "# predictorTest = shuffle.iloc[:,-1]\n",
        "\n",
        "# print out the first 6 rows of predictors.\n",
        "# print(predictors[:6])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2044 entries, 2017-10-30 to 2015-05-14\n",
            "Data columns (total 22 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   temp       2044 non-null   float64\n",
            " 1   slp        2044 non-null   float64\n",
            " 2   wdsp       2044 non-null   float64\n",
            " 3   April      2044 non-null   int64  \n",
            " 4   August     2044 non-null   int64  \n",
            " 5   December   2044 non-null   int64  \n",
            " 6   February   2044 non-null   int64  \n",
            " 7   January    2044 non-null   int64  \n",
            " 8   July       2044 non-null   int64  \n",
            " 9   June       2044 non-null   int64  \n",
            " 10  March      2044 non-null   int64  \n",
            " 11  May        2044 non-null   int64  \n",
            " 12  November   2044 non-null   int64  \n",
            " 13  October    2044 non-null   int64  \n",
            " 14  September  2044 non-null   int64  \n",
            " 15  Friday     2044 non-null   int64  \n",
            " 16  Monday     2044 non-null   int64  \n",
            " 17  Saturday   2044 non-null   int64  \n",
            " 18  Sunday     2044 non-null   int64  \n",
            " 19  Thursday   2044 non-null   int64  \n",
            " 20  Tuesday    2044 non-null   int64  \n",
            " 21  Wednesday  2044 non-null   int64  \n",
            "dtypes: float64(3), int64(19)\n",
            "memory usage: 367.3+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 511 entries, 2019-10-27 to 2013-08-17\n",
            "Data columns (total 22 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   temp       511 non-null    float64\n",
            " 1   slp        511 non-null    float64\n",
            " 2   wdsp       511 non-null    float64\n",
            " 3   April      511 non-null    int64  \n",
            " 4   August     511 non-null    int64  \n",
            " 5   December   511 non-null    int64  \n",
            " 6   February   511 non-null    int64  \n",
            " 7   January    511 non-null    int64  \n",
            " 8   July       511 non-null    int64  \n",
            " 9   June       511 non-null    int64  \n",
            " 10  March      511 non-null    int64  \n",
            " 11  May        511 non-null    int64  \n",
            " 12  November   511 non-null    int64  \n",
            " 13  October    511 non-null    int64  \n",
            " 14  September  511 non-null    int64  \n",
            " 15  Friday     511 non-null    int64  \n",
            " 16  Monday     511 non-null    int64  \n",
            " 17  Saturday   511 non-null    int64  \n",
            " 18  Sunday     511 non-null    int64  \n",
            " 19  Thursday   511 non-null    int64  \n",
            " 20  Tuesday    511 non-null    int64  \n",
            " 21  Wednesday  511 non-null    int64  \n",
            "dtypes: float64(3), int64(19)\n",
            "memory usage: 91.8+ KB\n",
            " \n",
            "date\n",
            "2017-10-30    0.445346\n",
            "2015-06-30    0.508846\n",
            "2018-04-12    0.516092\n",
            "2015-07-12    0.209363\n",
            "2018-03-16    0.440729\n",
            "Name: collisions, dtype: float64\n",
            "Length: 2044\n",
            "\n",
            "date\n",
            "2019-10-27    0.185617\n",
            "2018-01-08    0.583673\n",
            "2018-10-28    0.188135\n",
            "2017-04-23    0.201825\n",
            "2018-11-22    0.046875\n",
            "Name: collisions, dtype: float64\n",
            "Length: 511\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL2F4qYEvbAK"
      },
      "source": [
        "# print out the shuffled data (first 5 rows)\n",
        "# shuffle[:5]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IezylO-rvgE3"
      },
      "source": [
        "# # Select all rows for the 2nd column (i.e. 1)\n",
        "# targets = shuffle.iloc[:,22]\n",
        "\n",
        "# # print out the first 6 rows of the targets data.\n",
        "# print(targets[:6])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOENBOn-vitN"
      },
      "source": [
        "# A scale is not required here, but the constant will be useful in the assignment.\n",
        "SCALE_NUM_TRIPS = 1.0"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cri9VadSvm0m"
      },
      "source": [
        "# # Split our data into a training set i.e. 80% of the length of the shuffle array\n",
        "# trainsize = int(len(shuffle['NUM_TRIPS'])*0.8)\n",
        "# # The test set size is 100% - 80% = 20% of the length of the shuffle array.\n",
        "# testsize = len(shuffle['NUM_TRIPS']) - trainsize\n",
        "\n",
        "# # Define the number of input values (predictors)\n",
        "# nppredictors = 22\n",
        "# # Define the number of output values (targets)\n",
        "# noutputs = 1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo7CEhVHvukm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c33668-f709-440a-d512-22ab6d0953f7"
      },
      "source": [
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_house_regression_trained_model', ignore_errors=True)\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_house_regression_trained_model', hidden_units=[20,18,14], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "# Prints a log to show model is starting to train\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "# estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_NUM_TRIPS, steps=10000)\n",
        "estimator.fit(X_train, y_train/SCALE_NUM_TRIPS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=X_test)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores']*SCALE_NUM_TRIPS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((y_test - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the Life Satisfaction Values.\n",
        "avg = np.mean(y_train)\n",
        "\n",
        "# Calculate the RMSE using Life Satisfaction Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((y_test - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb8bc0deb38>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_house_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_house_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 13830.184, step = 1\n",
            "INFO:tensorflow:global_step/sec: 300.999\n",
            "INFO:tensorflow:loss = 0.076952666, step = 101 (0.334 sec)\n",
            "INFO:tensorflow:global_step/sec: 347.732\n",
            "INFO:tensorflow:loss = 0.07738731, step = 201 (0.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 324.775\n",
            "INFO:tensorflow:loss = 0.04758036, step = 301 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 342.69\n",
            "INFO:tensorflow:loss = 0.04899671, step = 401 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.85\n",
            "INFO:tensorflow:loss = 0.04266755, step = 501 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 340.101\n",
            "INFO:tensorflow:loss = 0.038771983, step = 601 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 315.801\n",
            "INFO:tensorflow:loss = 0.039966553, step = 701 (0.317 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.625\n",
            "INFO:tensorflow:loss = 0.033588473, step = 801 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 328.631\n",
            "INFO:tensorflow:loss = 0.05409093, step = 901 (0.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 316.238\n",
            "INFO:tensorflow:loss = 0.036105096, step = 1001 (0.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.687\n",
            "INFO:tensorflow:loss = 0.037625745, step = 1101 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.727\n",
            "INFO:tensorflow:loss = 0.04524745, step = 1201 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 323.402\n",
            "INFO:tensorflow:loss = 0.04799684, step = 1301 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.987\n",
            "INFO:tensorflow:loss = 0.06971938, step = 1401 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.243\n",
            "INFO:tensorflow:loss = 0.098580286, step = 1501 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.998\n",
            "INFO:tensorflow:loss = 0.07023784, step = 1601 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 346.466\n",
            "INFO:tensorflow:loss = 0.2835647, step = 1701 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.213\n",
            "INFO:tensorflow:loss = 0.95364666, step = 1801 (0.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 346.138\n",
            "INFO:tensorflow:loss = 0.099282056, step = 1901 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 329.339\n",
            "INFO:tensorflow:loss = 0.03975638, step = 2001 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.405\n",
            "INFO:tensorflow:loss = 0.13067704, step = 2101 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.25\n",
            "INFO:tensorflow:loss = 0.03371599, step = 2201 (0.305 sec)\n",
            "INFO:tensorflow:global_step/sec: 338.678\n",
            "INFO:tensorflow:loss = 0.3022689, step = 2301 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 340.665\n",
            "INFO:tensorflow:loss = 0.07119523, step = 2401 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.002\n",
            "INFO:tensorflow:loss = 0.31626537, step = 2501 (0.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.561\n",
            "INFO:tensorflow:loss = 0.08562334, step = 2601 (0.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.829\n",
            "INFO:tensorflow:loss = 0.28500378, step = 2701 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 341.669\n",
            "INFO:tensorflow:loss = 0.10555212, step = 2801 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 334.417\n",
            "INFO:tensorflow:loss = 0.066005096, step = 2901 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 321.733\n",
            "INFO:tensorflow:loss = 0.2528986, step = 3001 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 341.004\n",
            "INFO:tensorflow:loss = 0.27351394, step = 3101 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 334.327\n",
            "INFO:tensorflow:loss = 0.077884145, step = 3201 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.672\n",
            "INFO:tensorflow:loss = 0.15678415, step = 3301 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 334.253\n",
            "INFO:tensorflow:loss = 0.2650525, step = 3401 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.198\n",
            "INFO:tensorflow:loss = 0.07839984, step = 3501 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 316.456\n",
            "INFO:tensorflow:loss = 0.065093905, step = 3601 (0.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 332.155\n",
            "INFO:tensorflow:loss = 0.033704054, step = 3701 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 334.178\n",
            "INFO:tensorflow:loss = 0.042354375, step = 3801 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.892\n",
            "INFO:tensorflow:loss = 0.03373662, step = 3901 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 340.084\n",
            "INFO:tensorflow:loss = 0.036794275, step = 4001 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.996\n",
            "INFO:tensorflow:loss = 0.052852023, step = 4101 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 313.837\n",
            "INFO:tensorflow:loss = 0.033601217, step = 4201 (0.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.432\n",
            "INFO:tensorflow:loss = 0.09748256, step = 4301 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 314.223\n",
            "INFO:tensorflow:loss = 0.07217369, step = 4401 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 309.551\n",
            "INFO:tensorflow:loss = 0.03912288, step = 4501 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 330.029\n",
            "INFO:tensorflow:loss = 0.113896854, step = 4601 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 323.057\n",
            "INFO:tensorflow:loss = 0.034745626, step = 4701 (0.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 330.633\n",
            "INFO:tensorflow:loss = 0.15293366, step = 4801 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.44\n",
            "INFO:tensorflow:loss = 0.08636287, step = 4901 (0.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 312.505\n",
            "INFO:tensorflow:loss = 0.08048429, step = 5001 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 315.78\n",
            "INFO:tensorflow:loss = 0.038032196, step = 5101 (0.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 336.047\n",
            "INFO:tensorflow:loss = 0.031798687, step = 5201 (0.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 332.29\n",
            "INFO:tensorflow:loss = 0.1928707, step = 5301 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 328.668\n",
            "INFO:tensorflow:loss = 0.10382672, step = 5401 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 331.869\n",
            "INFO:tensorflow:loss = 0.0553953, step = 5501 (0.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 313.096\n",
            "INFO:tensorflow:loss = 0.05179216, step = 5601 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 321.266\n",
            "INFO:tensorflow:loss = 0.052044965, step = 5701 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 336.535\n",
            "INFO:tensorflow:loss = 0.052393924, step = 5801 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.883\n",
            "INFO:tensorflow:loss = 0.050046735, step = 5901 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 306.131\n",
            "INFO:tensorflow:loss = 0.048810378, step = 6001 (0.327 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.388\n",
            "INFO:tensorflow:loss = 0.0513943, step = 6101 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.856\n",
            "INFO:tensorflow:loss = 0.049284913, step = 6201 (0.305 sec)\n",
            "INFO:tensorflow:global_step/sec: 322.517\n",
            "INFO:tensorflow:loss = 0.060705796, step = 6301 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.019\n",
            "INFO:tensorflow:loss = 0.055830725, step = 6401 (0.305 sec)\n",
            "INFO:tensorflow:global_step/sec: 338.836\n",
            "INFO:tensorflow:loss = 0.041656263, step = 6501 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.486\n",
            "INFO:tensorflow:loss = 0.04559223, step = 6601 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.889\n",
            "INFO:tensorflow:loss = 0.044967815, step = 6701 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.469\n",
            "INFO:tensorflow:loss = 0.048330985, step = 6801 (0.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 304.689\n",
            "INFO:tensorflow:loss = 0.050024338, step = 6901 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.093\n",
            "INFO:tensorflow:loss = 0.044514067, step = 7001 (0.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.163\n",
            "INFO:tensorflow:loss = 0.037837736, step = 7101 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 330.685\n",
            "INFO:tensorflow:loss = 0.04662705, step = 7201 (0.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.321\n",
            "INFO:tensorflow:loss = 0.04206185, step = 7301 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 348.254\n",
            "INFO:tensorflow:loss = 0.049438808, step = 7401 (0.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 321.64\n",
            "INFO:tensorflow:loss = 0.051054336, step = 7501 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.917\n",
            "INFO:tensorflow:loss = 0.054193128, step = 7601 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 336.882\n",
            "INFO:tensorflow:loss = 0.040860593, step = 7701 (0.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 341.518\n",
            "INFO:tensorflow:loss = 0.0549511, step = 7801 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 340.13\n",
            "INFO:tensorflow:loss = 0.054567534, step = 7901 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 322.939\n",
            "INFO:tensorflow:loss = 0.05898357, step = 8001 (0.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 319.143\n",
            "INFO:tensorflow:loss = 0.04114446, step = 8101 (0.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 347.675\n",
            "INFO:tensorflow:loss = 0.04571116, step = 8201 (0.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 304.651\n",
            "INFO:tensorflow:loss = 0.049317595, step = 8301 (0.324 sec)\n",
            "INFO:tensorflow:global_step/sec: 324.672\n",
            "INFO:tensorflow:loss = 0.050846856, step = 8401 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 324.9\n",
            "INFO:tensorflow:loss = 0.056081176, step = 8501 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.417\n",
            "INFO:tensorflow:loss = 0.052362777, step = 8601 (0.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 331.962\n",
            "INFO:tensorflow:loss = 0.05480412, step = 8701 (0.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.479\n",
            "INFO:tensorflow:loss = 0.052426055, step = 8801 (0.303 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.487\n",
            "INFO:tensorflow:loss = 0.04727924, step = 8901 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 323.774\n",
            "INFO:tensorflow:loss = 0.05404059, step = 9001 (0.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 341.959\n",
            "INFO:tensorflow:loss = 0.051545836, step = 9101 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.085\n",
            "INFO:tensorflow:loss = 0.050531767, step = 9201 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 324.351\n",
            "INFO:tensorflow:loss = 0.04428017, step = 9301 (0.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.479\n",
            "INFO:tensorflow:loss = 0.048817575, step = 9401 (0.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.984\n",
            "INFO:tensorflow:loss = 0.059327886, step = 9501 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 332.618\n",
            "INFO:tensorflow:loss = 0.054666307, step = 9601 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 307.461\n",
            "INFO:tensorflow:loss = 0.044131316, step = 9701 (0.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.061\n",
            "INFO:tensorflow:loss = 0.046113133, step = 9801 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 331.882\n",
            "INFO:tensorflow:loss = 0.051071912, step = 9901 (0.305 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_house_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.04384181.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_house_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "DNNRegression has RMSE of 0.2245394301739037\n",
            "Just using average = 0.43449792651030533 has RMSE of 0.22449141565774594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddhgd-Pk1qLm"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "preds2 = pd.DataFrame.from_dict(data=preds)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "9TB-fVgX1uT1",
        "outputId": "18c5be56-28f4-449a-e9c0-645a9f905748"
      },
      "source": [
        "sns.regplot(y_test,preds2.scores)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb8c1166400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "tjiMBNJM1xpF",
        "outputId": "a92cd527-4bbd-43bc-cea5-9334e78d59ea"
      },
      "source": [
        "sns.displot(y_test.reset_index(drop=True) - preds2.scores, kind='kde');"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp0ptPOv14JV",
        "outputId": "71fa5d88-ea7f-4388-a91b-f18bd7224759"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "\r\n",
        "print('MAE:', metrics.mean_absolute_error(y_test, preds2))\r\n",
        "print('MSE:', metrics.mean_squared_error(y_test, preds2))\r\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, preds2)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 0.186805686903951\n",
            "MSE: 0.05041795570282136\n",
            "RMSE: 0.22453943017390365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KxRETghymhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66942c54-ea15-4483-fdec-3d1a50a3969d"
      },
      "source": [
        "#\"Apr\",\"Aug\",\"Dec\",\"Feb\",\"Jan\",\"Jul\",\"Jun\",\"Mar\",\"May\",\"Nov\",\"Oct\",\"Sep\",\"Fri\",\"Mon\",\"Sat\",\"Sun\",\"Thu\",\"Tue\",\"Wed\",\"year\",\"temp\",\"wdsp\",\"NUM_TRIPS\"\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "         'Apr' : [0,0,0],\n",
        "         'Aug' : [1,0,0],\n",
        "         'Dec' : [0,1,0],\n",
        "         'Feb' : [0,0,1],\n",
        "         'Jan' : [0,0,0],\n",
        "         'Jul' : [0,0,0],\n",
        "         'Jun' : [0,0,0],\n",
        "         'Mar' : [0,0,0],\n",
        "         'May' : [0,0,0],\n",
        "         'Nov' : [0,0,0],\n",
        "         'Oct' : [0,0,0],\n",
        "         'Sep' : [0,0,0],\n",
        "         'Fri' : [0,0,0],\n",
        "         'Mon' : [1,1,1],\n",
        "         'Sat' : [0,0,0],\n",
        "         'Sun' : [0,0,0],\n",
        "         'Thu' : [0,0,0],\n",
        "         'Tue' : [0,0,0],\n",
        "         'Wed' : [0,0,0],\n",
        "         'year' : [2009,2009,2009],\n",
        "         'temp' : [61.8, 31.2, 40.0],\n",
        "        #  'slp' : [1023, 1002, 985],\n",
        "         'wdsp' : [5.0, 3.0, 8.0]\n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_house_regression_trained_model', hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator.predict(x=input)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb8c1347e80>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_house_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_house_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[1.7543439 3.4192574 2.8166134]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lalzD8Gb2S6G"
      },
      "source": [
        "For the first, you can see below, we are in August, Saturday (we have a monday), 2009. We have a lower temperature and lower windspeed. The difference in day is likely to account for the higher actual number of trips.\n",
        "\n",
        "205\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t2009\t64.9\t4.2\t0.700748221591537\n",
        "\n",
        "For second (December):\n",
        "\n",
        "337\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t2009\t35.2\t6.6\t0.62902717790116\n",
        "\n",
        "For third (February):\n",
        "\n",
        "28\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t2009\t38.1\t3.6\t0.675798566550843\n",
        "\n",
        "The results overall look reasonable. You can look into this further. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbvoHSqq33ut"
      },
      "source": [
        "Considerations for Assignment. I would likely use another method to either standardise or normalise num_trips. And perhaps not bother and scale them in here with SCALE_NUM_TRIPS with a generally large number.\n",
        "\n",
        "Obviously, you will likely want to have a number of variations but there is no reason you can't use most of the data given. Remember, the DNN is trying to solve a complex relationship, not a linear one. \n",
        "\n",
        "Other things to consider when doing this would be to take validation. Of course, in the assignment you will have a much larger range of data i.e. from some date x to y.\n",
        "\n",
        "This will give you more data. Taking real validation data that hasn't been shown to the model will give real results for you to check against rather than what I have done here (which is just for information)."
      ]
    }
  ]
}